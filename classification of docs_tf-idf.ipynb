{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "335_Word2Vec_Task2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwwkpADKyeUS"
      },
      "source": [
        "# Importing all the necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCRuJpTJycIv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "40fb62d8-4587-40e7-cfc2-0bf2eedfaac0"
      },
      "source": [
        "from nltk.corpus import reuters \r\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\r\n",
        "import pandas as pd\r\n",
        "import spacy\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "'''\r\n",
        "  https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html\r\n",
        "  https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\r\n",
        "  https://spacy.io/usage/vectors-similarity\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n  https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html\\n  https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\\n  https://spacy.io/usage/vectors-similarity\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xm9uz654ye-7",
        "outputId": "a778e17b-2546-4529-814a-e5127559e4e3"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('reuters')\r\n",
        "!python -m spacy download en_core_web_lg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "Collecting en_core_web_lg==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz (827.9MB)\n",
            "\u001b[K     |████████████████████████████████| 827.9MB 1.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_lg==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (51.1.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.3.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.7.4.3)\n",
            "Building wheels for collected packages: en-core-web-lg\n",
            "  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-lg: filename=en_core_web_lg-2.2.5-cp36-none-any.whl size=829180945 sha256=7a8fc23fed4ae020777c1c624b6ca4673d567ea3b89aa86cc7253ea9851b743f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-lh804lp4/wheels/2a/c1/a6/fc7a877b1efca9bc6a089d6f506f16d3868408f9ff89f8dbfc\n",
            "Successfully built en-core-web-lg\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVJkzlpoygxe",
        "outputId": "31c36d3f-9dc0-4e17-ce21-b3079f3a45ce"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HgMwpI0ylJP",
        "outputId": "41fdf155-5363-4880-c514-9a892def6dfa"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('punkt')\r\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNhgkF0q0WT_"
      },
      "source": [
        "# Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlWL3zjlzvVQ"
      },
      "source": [
        "mlb = MultiLabelBinarizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dN0IKFN1NgR"
      },
      "source": [
        "def collection_stats():\r\n",
        "  documents = reuters.fileids()\r\n",
        "  print(str(len(documents)) + \" documents\");\r\n",
        "\r\n",
        "  train_docs = list(filter(lambda doc: doc.startswith(\"train\"), documents));\r\n",
        "  print(str(len(train_docs)) + \" total train documents\");\r\n",
        " \r\n",
        "  test_docs = list(filter(lambda doc: doc.startswith(\"test\"), documents));\r\n",
        "  print(str(len(test_docs)) + \" total test documents\")\r\n",
        "\r\n",
        "  categories = reuters.categories()\r\n",
        "\r\n",
        "  print(str(len(categories)) + \" categories\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfBPxUot1e9s",
        "outputId": "c4ed7e9c-cf4c-4044-bef3-776f2da511a4"
      },
      "source": [
        "collection_stats()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10788 documents\n",
            "7769 total train documents\n",
            "3019 total test documents\n",
            "90 categories\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIl-WZB91i6U"
      },
      "source": [
        "# Train Test Split of Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjsuV-8O1gXp"
      },
      "source": [
        "def train_test_split():\r\n",
        "  documents = reuters.fileids()\r\n",
        "  train_docs = [document for document in documents if document.startswith(\"train\")]\r\n",
        "  test_docs = [document for document in documents if document.startswith(\"test\")]\r\n",
        "  x_train = [reuters.raw(doc_id) for doc_id in train_docs]\r\n",
        "  y_train = [reuters.raw(doc_id) for doc_id in test_docs]\r\n",
        "  x_test = mlb.fit_transform([reuters.categories(doc_id) for doc_id in train_docs])\r\n",
        "  y_test = mlb.transform([reuters.categories(doc_id) for doc_id in test_docs])\r\n",
        "  return x_train, y_train, x_test, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fobAnGh1lYA"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aozDGMZL1pR4"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9S5IqN31m5z"
      },
      "source": [
        "import re\r\n",
        "import nltk\r\n",
        "from nltk.tokenize import word_tokenize\r\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHTHz5OS11KR"
      },
      "source": [
        "stop_words = set(stopwords.words('english'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPkbzO9-1sJD"
      },
      "source": [
        "def clean_text(X_train):\r\n",
        "  clean =[]\r\n",
        "  for term in X_train:\r\n",
        "    term=re.sub(r'https\\S+' , '' ,term)\r\n",
        "    term=re.sub('[^a-zA-Z]' , ' ', term)\r\n",
        "    term = str(term).lower()\r\n",
        "    term=word_tokenize(term)\r\n",
        "    term=[item for item in term if item not in stop_words]\r\n",
        "    term =' '.join(term)\r\n",
        "    clean.append(term)\r\n",
        "  return clean\r\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvZpciiv1uHK"
      },
      "source": [
        "X_train=clean_text(x_train)\r\n",
        "X_test =clean_text(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HW-AP9OF16U8"
      },
      "source": [
        "# Word2Vec Representation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PA0hQ43Z2cVb"
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_lg\")\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2apRo7SF1-Kb"
      },
      "source": [
        "def get_word_vectors(sentence):\r\n",
        "  tokens = nlp(sentence)\r\n",
        "  vector=np.sum([token.vector for token in tokens] ,axis =0)\r\n",
        "  return vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEp5fOQ_LH_g"
      },
      "source": [
        "## Generate Word2Vec embeddings for training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3pLADI52POJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82f76358-af5d-4f4a-de58-25d424117ac4"
      },
      "source": [
        "get_word_vectors(X_train[0]).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8o-RyXUzB8Ws"
      },
      "source": [
        "x_word2vec_train=[get_word_vectors(doc) for doc in X_train]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LJ9oYpPCdnG",
        "outputId": "4576795c-b85a-4cc9-fff5-62888ec231d4"
      },
      "source": [
        "np.shape(x_word2vec_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7769, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pExa8RTLRgv"
      },
      "source": [
        "## Generate Word2Vec embeddings for testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnNhAoVI2RaA"
      },
      "source": [
        "x_word2vec_test=[get_word_vectors(doc) for doc in X_test]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imbSelEbFA4D",
        "outputId": "f3df4305-3a9e-46ad-b200-06b0077969fe"
      },
      "source": [
        "np.shape(x_word2vec_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3019, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ue2jfi1D433s"
      },
      "source": [
        "# Logistic Regression "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7B_oYpcC3spK"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.multiclass import OneVsRestClassifier\r\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7PhwrmvLYys"
      },
      "source": [
        "## Fit and Predict Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tb6XcGmS5VO2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ed16a7d-dcfd-4b38-de1c-6056ea53fc3e"
      },
      "source": [
        "lr=OneVsRestClassifier(LogisticRegression(solver='newton-cg'))\r\n",
        "lr.fit(x_word2vec_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OneVsRestClassifier(estimator=LogisticRegression(C=1.0, class_weight=None,\n",
              "                                                 dual=False, fit_intercept=True,\n",
              "                                                 intercept_scaling=1,\n",
              "                                                 l1_ratio=None, max_iter=100,\n",
              "                                                 multi_class='auto',\n",
              "                                                 n_jobs=None, penalty='l2',\n",
              "                                                 random_state=None,\n",
              "                                                 solver='newton-cg', tol=0.0001,\n",
              "                                                 verbose=0, warm_start=False),\n",
              "                    n_jobs=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoQXdO4a5XFx"
      },
      "source": [
        "y_pred1 = lr.predict(x_word2vec_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fLv0ZMBLeZH"
      },
      "source": [
        "## Classification report on training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yylwQMfs55js"
      },
      "source": [
        "#not needed\r\n",
        "#print(\"Word2vec Result word on Train\")\r\n",
        "3print(classification_report( ovr.predict(X_train) , y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_tyMYyDLm62"
      },
      "source": [
        "## Classification report on testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9siC3g45ats",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee5cb477-0295-43c9-fb53-746553e07e47"
      },
      "source": [
        "print(\"Word2vec Result word on Test\")\r\n",
        "print(classification_report( lr.predict(x_word2vec_test) , y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word2vec Result word on Test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.94      0.92       702\n",
            "           1       0.30      0.78      0.44         9\n",
            "           2       0.71      0.83      0.77        12\n",
            "           3       0.63      0.73      0.68        26\n",
            "           4       0.78      0.67      0.72        21\n",
            "           5       0.00      0.00      0.00         0\n",
            "           6       0.78      0.70      0.74        20\n",
            "           7       0.50      1.00      0.67         1\n",
            "           8       0.00      0.00      0.00         1\n",
            "           9       0.93      0.79      0.85        33\n",
            "          10       0.78      0.82      0.80        17\n",
            "          11       0.00      0.00      0.00         1\n",
            "          12       0.79      0.65      0.71        68\n",
            "          13       0.55      0.69      0.61        16\n",
            "          14       0.00      0.00      0.00         0\n",
            "          15       0.64      0.67      0.65        27\n",
            "          16       0.00      0.00      0.00         0\n",
            "          17       0.84      0.75      0.79       211\n",
            "          18       0.00      0.00      0.00         0\n",
            "          19       0.59      0.54      0.57        48\n",
            "          20       0.00      0.00      0.00         0\n",
            "          21       0.98      0.96      0.97      1106\n",
            "          22       0.40      0.36      0.38        11\n",
            "          23       0.65      0.69      0.67        16\n",
            "          24       0.94      0.89      0.92        37\n",
            "          25       0.63      0.86      0.73        22\n",
            "          26       0.84      0.89      0.86       141\n",
            "          27       0.00      0.00      0.00         0\n",
            "          28       0.00      0.00      0.00         1\n",
            "          29       0.40      0.18      0.25        11\n",
            "          30       0.50      0.75      0.60         4\n",
            "          31       0.75      0.75      0.75         4\n",
            "          32       0.43      1.00      0.60         3\n",
            "          33       0.00      0.00      0.00         0\n",
            "          34       0.64      0.57      0.60       147\n",
            "          35       0.83      0.83      0.83        12\n",
            "          36       0.36      0.42      0.38        12\n",
            "          37       0.00      0.00      0.00         3\n",
            "          38       0.76      0.80      0.78        20\n",
            "          39       0.00      0.00      0.00         0\n",
            "          40       0.29      1.00      0.44         4\n",
            "          41       1.00      0.75      0.86         4\n",
            "          42       0.00      0.00      0.00         2\n",
            "          43       0.58      0.50      0.54        28\n",
            "          44       0.50      1.00      0.67         3\n",
            "          45       0.26      0.56      0.36         9\n",
            "          46       0.73      0.66      0.70       197\n",
            "          47       0.74      0.62      0.68        40\n",
            "          48       0.25      1.00      0.40         1\n",
            "          49       0.40      0.60      0.48        20\n",
            "          50       0.00      0.00      0.00         0\n",
            "          51       0.00      0.00      0.00         0\n",
            "          52       0.00      0.00      0.00         1\n",
            "          53       0.33      1.00      0.50         2\n",
            "          54       0.70      0.56      0.62        59\n",
            "          55       0.64      0.78      0.70         9\n",
            "          56       0.00      0.00      0.00         0\n",
            "          57       0.40      0.67      0.50         6\n",
            "          58       0.00      0.00      0.00         1\n",
            "          59       0.42      0.71      0.53         7\n",
            "          60       0.14      1.00      0.25         1\n",
            "          61       0.00      0.00      0.00         2\n",
            "          62       0.00      0.00      0.00         1\n",
            "          63       0.00      0.00      0.00         0\n",
            "          64       0.00      0.00      0.00         1\n",
            "          65       0.44      0.57      0.50         7\n",
            "          66       0.72      0.81      0.76        16\n",
            "          67       0.50      1.00      0.67         1\n",
            "          68       0.42      0.83      0.56        12\n",
            "          69       0.50      1.00      0.67         6\n",
            "          70       0.00      0.00      0.00         0\n",
            "          71       0.67      0.82      0.74        73\n",
            "          72       0.50      1.00      0.67         4\n",
            "          73       0.40      0.50      0.44         8\n",
            "          74       0.46      0.86      0.60         7\n",
            "          75       0.45      0.71      0.56         7\n",
            "          76       0.73      0.59      0.65        41\n",
            "          77       0.18      0.33      0.24         6\n",
            "          78       0.86      0.84      0.85        37\n",
            "          79       0.00      0.00      0.00         1\n",
            "          80       0.00      0.00      0.00         0\n",
            "          81       0.20      1.00      0.33         1\n",
            "          82       0.00      0.00      0.00         1\n",
            "          83       0.58      1.00      0.74         7\n",
            "          84       0.69      0.53      0.60       154\n",
            "          85       0.43      0.64      0.52        25\n",
            "          86       0.79      0.80      0.79        70\n",
            "          87       0.70      1.00      0.82         7\n",
            "          88       0.14      0.20      0.17        10\n",
            "          89       0.62      0.89      0.73         9\n",
            "\n",
            "   micro avg       0.80      0.82      0.81      3671\n",
            "   macro avg       0.41      0.53      0.44      3671\n",
            "weighted avg       0.82      0.82      0.82      3671\n",
            " samples avg       0.85      0.82      0.83      3671\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rmz7Vycr6BvZ"
      },
      "source": [
        "# Naive Bayes Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qib7wcxa5vf8"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "from sklearn.multiclass import OneVsRestClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVQ3fFc-L8u3"
      },
      "source": [
        "## Fit and Predict Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__2S1xz3L7iB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eec868c5-faf7-4ce7-ae44-4f73deebfa8a"
      },
      "source": [
        "gnb = OneVsRestClassifier(GaussianNB())\r\n",
        "gnb.fit(x_word2vec_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OneVsRestClassifier(estimator=GaussianNB(priors=None, var_smoothing=1e-09),\n",
              "                    n_jobs=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cYJDqV96I6T"
      },
      "source": [
        "y_pred2=gnb.predict(x_word2vec_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-D3XgyIL3VW"
      },
      "source": [
        "## Classification report on training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxJfnEH_6QLP"
      },
      "source": [
        "#print(\"Naive Bayes Classifier Result word on Train\")\r\n",
        "#print(classification_report(nbClassifier.predict(X_train) , y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38n3Zg87Lu1s"
      },
      "source": [
        "## Classification report on testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTibGEl26dCi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d915619-3163-44a3-f515-17265a0ac58a"
      },
      "source": [
        "print(\"Naive Bayes Classifier Result word on Test\")\r\n",
        "print(classification_report(gnb.predict(x_word2vec_test) , y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Naive Bayes Classifier Result word on Test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.34      0.50      1918\n",
            "           1       0.70      0.03      0.05       640\n",
            "           2       0.86      0.05      0.09       260\n",
            "           3       0.47      0.04      0.08       319\n",
            "           4       0.78      0.09      0.17       149\n",
            "           5       0.00      0.00      0.00         0\n",
            "           6       0.28      0.02      0.03       305\n",
            "           7       0.00      0.00      0.00        38\n",
            "           8       0.67      0.10      0.17        20\n",
            "           9       0.36      0.03      0.06       333\n",
            "          10       0.72      0.02      0.04       631\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.43      0.07      0.12       331\n",
            "          13       0.65      0.08      0.15       154\n",
            "          14       0.00      0.00      0.00         0\n",
            "          15       0.57      0.12      0.19       137\n",
            "          16       1.00      1.00      1.00         1\n",
            "          17       0.43      0.18      0.26       438\n",
            "          18       0.00      0.00      0.00         0\n",
            "          19       0.45      0.13      0.21       149\n",
            "          20       0.25      0.00      0.00       498\n",
            "          21       0.93      0.48      0.63      2117\n",
            "          22       0.40      0.11      0.17        38\n",
            "          23       0.35      0.02      0.04       305\n",
            "          24       0.89      0.10      0.18       316\n",
            "          25       0.77      0.34      0.47        68\n",
            "          26       0.44      0.18      0.26       368\n",
            "          27       0.00      0.00      0.00         1\n",
            "          28       0.00      0.00      0.00         0\n",
            "          29       0.20      0.01      0.02        78\n",
            "          30       0.50      0.01      0.01       561\n",
            "          31       0.50      0.03      0.06        61\n",
            "          32       0.71      0.11      0.19        45\n",
            "          33       0.00      0.00      0.00         0\n",
            "          34       0.40      0.31      0.35       169\n",
            "          35       0.33      0.03      0.05       139\n",
            "          36       0.29      0.02      0.03       217\n",
            "          37       1.00      0.01      0.02        95\n",
            "          38       0.52      0.09      0.15       124\n",
            "          39       0.00      0.00      0.00        76\n",
            "          40       0.57      0.05      0.09       157\n",
            "          41       1.00      0.01      0.01       434\n",
            "          42       0.00      0.00      0.00         0\n",
            "          43       0.50      0.06      0.10       216\n",
            "          44       0.50      0.50      0.50         6\n",
            "          45       0.74      0.10      0.17       145\n",
            "          46       0.34      0.20      0.25       307\n",
            "          47       0.56      0.11      0.19       166\n",
            "          48       0.00      0.00      0.00         0\n",
            "          49       0.27      0.02      0.04       332\n",
            "          50       0.00      0.00      0.00       147\n",
            "          51       0.00      0.00      0.00         0\n",
            "          52       0.00      0.00      0.00         0\n",
            "          53       0.33      0.03      0.06        64\n",
            "          54       0.47      0.07      0.12       330\n",
            "          55       0.73      0.01      0.01      1342\n",
            "          56       0.00      0.00      0.00         0\n",
            "          57       0.60      0.04      0.08       149\n",
            "          58       0.00      0.00      0.00         0\n",
            "          59       0.58      0.08      0.14        90\n",
            "          60       0.00      0.00      0.00         0\n",
            "          61       0.33      1.00      0.50         1\n",
            "          62       0.00      0.00      0.00         0\n",
            "          63       0.00      0.00      0.00         0\n",
            "          64       0.00      0.00      0.00         4\n",
            "          65       0.44      0.05      0.10        74\n",
            "          66       0.61      0.10      0.17       108\n",
            "          67       1.00      0.01      0.02       217\n",
            "          68       0.54      0.08      0.15       153\n",
            "          69       0.17      0.01      0.01       297\n",
            "          70       0.00      0.00      0.00         0\n",
            "          71       0.93      0.34      0.50       246\n",
            "          72       0.50      0.11      0.17        38\n",
            "          73       0.50      0.03      0.05       196\n",
            "          74       0.54      0.05      0.09       148\n",
            "          75       0.64      0.04      0.07       182\n",
            "          76       0.48      0.05      0.09       321\n",
            "          77       0.64      0.02      0.04       369\n",
            "          78       0.31      0.03      0.06       344\n",
            "          79       0.00      0.00      0.00         0\n",
            "          80       0.00      0.00      0.00        22\n",
            "          81       0.40      0.02      0.04       101\n",
            "          82       0.25      0.00      0.01       246\n",
            "          83       0.25      0.01      0.02       275\n",
            "          84       0.54      0.15      0.24       416\n",
            "          85       0.73      0.12      0.20       234\n",
            "          86       0.45      0.10      0.17       310\n",
            "          87       0.30      0.07      0.12        40\n",
            "          88       0.36      0.02      0.04       250\n",
            "          89       0.85      0.03      0.07       319\n",
            "\n",
            "   micro avg       0.70      0.13      0.22     19895\n",
            "   macro avg       0.41      0.09      0.12     19895\n",
            "weighted avg       0.62      0.13      0.19     19895\n",
            " samples avg       0.74      0.31      0.39     19895\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IH4EYVj6jtG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}