{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "335_Dialogue Management Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7auJCfornYb4"
      },
      "source": [
        "# download glove embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouoOmsRqnXQ7",
        "outputId": "da232646-e7ee-4d21-d0eb-fbea02179d06"
      },
      "source": [
        "!wget https://gist.githubusercontent.com/bastings/b094de2813da58056a05e8e7950d4ad1/raw/3fbd3976199c2b88de2ae62afc0ecc6f15e6f7ce/glove.840B.300d.sst.txt\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-16 17:37:20--  https://gist.githubusercontent.com/bastings/b094de2813da58056a05e8e7950d4ad1/raw/3fbd3976199c2b88de2ae62afc0ecc6f15e6f7ce/glove.840B.300d.sst.txt\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 53933315 (51M) [text/plain]\n",
            "Saving to: ‘glove.840B.300d.sst.txt’\n",
            "\n",
            "glove.840B.300d.sst 100%[===================>]  51.43M  87.2MB/s    in 0.6s    \n",
            "\n",
            "2021-01-16 17:37:21 (87.2 MB/s) - ‘glove.840B.300d.sst.txt’ saved [53933315/53933315]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3MdWBMBn_Js"
      },
      "source": [
        "!cp glove.840B.300d.sst.txt sample_data/glove.840B.300d.sst.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ST_XrSLKUZ1A"
      },
      "source": [
        "#import necessary packages\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBdKVsalMOTG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "846e06b4-963f-46be-ff8f-fbb8236bd58b"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import re\n",
        "import itertools\n",
        "from collections import Counter\n",
        "#from New_Utils import *\n",
        "# from keras.layers import Input, Dense, Embedding, Conv2D, MaxPool2D, LSTM\n",
        "# from keras.layers import Reshape, Flatten, Dropout, Concatenate\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "# from keras.optimizers import Adam\n",
        "from keras.optimizers import *\n",
        "from keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "# from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "# from keras.layers import Dense\n",
        "from keras.layers import *\n",
        "# from keras.layers.convolutional import Conv1D\n",
        "# from keras.layers.convolutional import MaxPooling1D\n",
        "# from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.regularizers import *\n",
        "import tensorflow as tf\n",
        "# from keras.layers.normalization import BatchNormalization\n",
        "from keras.preprocessing.text import *\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "#from Text_Preprocessing import *\n",
        "import timeit"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLzdBLh7UzyJ"
      },
      "source": [
        "#load necessary supporting functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GdaJ6_vMTRX"
      },
      "source": [
        "def dumpPickle(path,object_to_dump):\n",
        "\tf=open(path,'wb')\n",
        "\tpickle.dump(object_to_dump,f)\n",
        "\tf.close()\n",
        "\n",
        "#Reads an object stores at 'path'\n",
        "def readPickle(path):\n",
        "\tf=open(path,'rb')\n",
        "\tob_to_load=pickle.load(f)\n",
        "\tf.close()\n",
        "\treturn ob_to_load\n",
        "\n",
        "\n",
        "#Loads an embedding matrix stores at emb_pickle_path if doesn't exists a pickled file, then creates One which is initialized by normal distribution with mean and std dev of the embeddings used, if given the option to save it saves\n",
        "#the newly created embedding matrix at saveName\n",
        "def load_create_embedding_matrix(word_index,vocab_size,emb_dim,emb_path,emb_pickle_path=False,save=False,saveName=None):\n",
        "\tif not emb_pickle_path:\n",
        "\t\tembedding_dict={}\n",
        "\t\tf=open(emb_path,'rb')\n",
        "\t\tfor line in f:\n",
        "\t\t\tfields=line.split()\n",
        "\t\t\tword=fields[0]\n",
        "\t\t\tw_e=np.asarray(fields[1:],dtype='float32')\n",
        "\t\t\tembedding_dict[word]=w_e\n",
        "\t\tf.close()\n",
        "\t\tallembs=np.stack(embedding_dict.values())\n",
        "\t\temb_mean,emb_std=allembs.mean(),allembs.std()\n",
        "\t\tembedding_matrix=np.random.normal(emb_mean,emb_std,(vocab_size,emb_dim))\n",
        "\t\tfor word,index in word_index.items():\n",
        "\t\t\t#print(word)\n",
        "\t\t\tvector=embedding_dict.get(word)\n",
        "\t\t\tif vector is not None:\n",
        "\t\t\t\tembedding_matrix[index]=vector\n",
        "\t\tif save:\n",
        "\t\t\tdumpPickle(saveName,embedding_matrix)\n",
        "\telse:\n",
        "\t\tf=open(emb_pickle_path,'rb')\n",
        "\t\tembedding_matrix=pickle.load(f)\n",
        "\t\tf.close()\n",
        "\treturn embedding_matrix\n",
        "\n",
        "#creates a tokenizer from training data file in csv format, if there is one it loads and returns\n",
        "def load_create_tokenizer(train_data,tok_path=None,savetokenizer=False):\n",
        "\tif tok_path == None:\n",
        "\t\ttokenizer=Tokenizer()\n",
        "\t\ttokenizer.fit_on_texts(train_data)\n",
        "\t\tlen(tokenizer.word_index)\n",
        "\t\tif savetokenizer:\n",
        "\t\t\tdumpPickle('./New_Tokenizer.tkn',tokenizer)\n",
        "\telse:\n",
        "\t\ttokenizer=readPickle(tok_path)\n",
        "\treturn tokenizer\n",
        "\n",
        "def load_create_padded_data(X_train,savetokenizer,padPath=None,isPaddingDone=False,maxlen=None,tokenizer_path=None,save_new_padded_data=False,path_for_new_data=False):\n",
        "\t#print(tokenizer_path)\n",
        "\tif not isPaddingDone:\n",
        "\t\ttokenizer=load_create_tokenizer(X_train,tok_path=tokenizer_path,savetokenizer=savetokenizer)\n",
        "\t\t#word_index=tokenizer.word_index\n",
        "\t\tX_train=tokenizer.texts_to_sequences(X_train)\n",
        "\t\tX_train=pad_sequences(X_train,maxlen=maxlen)\n",
        "\t\tif save_new_padded_data:\n",
        "\t\t\tdumpPickle(path_for_new_data,X_train)\n",
        "\telse:\n",
        "\t\tX_train=readPickle(padPath)\n",
        "\treturn X_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sb41wKhuVWuK"
      },
      "source": [
        "#load dataset : utterances and its corresponding labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "xAqXIjr9ia4N",
        "outputId": "a906a30e-0ef5-4b9e-f5c3-449284745075"
      },
      "source": [
        "from google.colab import files \r\n",
        "  \r\n",
        "  \r\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3c0542f4-6f63-4ddf-9bec-e09bdae7df05\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3c0542f4-6f63-4ddf-9bec-e09bdae7df05\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving TWEET_DATA_IEEE_TCSS - Sheet1.csv to TWEET_DATA_IEEE_TCSS - Sheet1.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "KwfhwHPtjP_l",
        "outputId": "c8c52238-e162-4a7c-af84-450a35be511b"
      },
      "source": [
        "import io \r\n",
        "df = pd.read_csv(io.BytesIO(uploaded['TWEET_DATA_IEEE_TCSS - Sheet1.csv']), header= None)\r\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   0    1\n",
              "0  RT @Bipartisanism: Katie Couric just schooled ...  STM\n",
              "1  RT @stevesilberman: If you missed it: Sick bur...  EXP\n",
              "2  @jk_rowling & the Never-Ending Story: With a #...  QUE\n",
              "3  RT @somebadideas: The emotional & personal eff...  EXP\n",
              "4  RT @jk_rowling: A 9-year-old Nigerian girl has...  STM"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RT @Bipartisanism: Katie Couric just schooled ...</td>\n",
              "      <td>STM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RT @stevesilberman: If you missed it: Sick bur...</td>\n",
              "      <td>EXP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@jk_rowling &amp; the Never-Ending Story: With a #...</td>\n",
              "      <td>QUE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RT @somebadideas: The emotional &amp; personal eff...</td>\n",
              "      <td>EXP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT @jk_rowling: A 9-year-old Nigerian girl has...</td>\n",
              "      <td>STM</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cytG6e2cljZ-"
      },
      "source": [
        "text=df[0].tolist()\r\n",
        "labels=df[1].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SonuvJhqo56",
        "outputId": "d6f51ef0-9159-4a69-c9fa-098cf2d8282e"
      },
      "source": [
        "print(len(df))\r\n",
        "print(len(text))\r\n",
        "print(len(labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7500\n",
            "7500\n",
            "7500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b27_HkXGq9QP"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNIGfxU-lwv5"
      },
      "source": [
        "train_Text, test_Text, train_l, test_label = train_test_split(text, labels, test_size=0.20, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHRZI8_PMchf"
      },
      "source": [
        "train_Text = [s.strip() for s in train_Text]\n",
        "test_Text = [s.strip() for s in test_Text]\n",
        "\n",
        "text = train_Text + test_Text\n",
        "max1=0\n",
        "\n",
        "for i in range(0,len(text)):\n",
        "\tdata=text[i].split(\" \")\n",
        "\tmax2=len(data)\n",
        "\tif(max2>max1):\n",
        "\t\tmax1=max2\n",
        "\n",
        "sequence_length = max1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aLa_qKSVecu"
      },
      "source": [
        "#create padded data and embedding matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqAIFkp2Mpd7",
        "outputId": "9835f9e2-1c90-4ced-ff3d-39d310fa3f41"
      },
      "source": [
        "print(\"creating data\")\n",
        "tokenizer=load_create_tokenizer(train_Text,None,True)\n",
        "X_train=load_create_padded_data(X_train=train_Text,savetokenizer=False,isPaddingDone=False,maxlen=sequence_length,tokenizer_path='./New_Tokenizer.tkn')\n",
        "X_test=load_create_padded_data(X_train=test_Text,savetokenizer=False,isPaddingDone=False,maxlen=sequence_length,tokenizer_path='./New_Tokenizer.tkn')\n",
        "word_index=tokenizer.word_index\n",
        "embedding_matrix=load_create_embedding_matrix(word_index,len(word_index)+1,300,'./glove.840B.300d.sst.txt',False,True,'./Emb_Mat.mat')\n",
        "\n",
        "print(\"data created\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "creating data\n",
            "data created\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkHjPUgJMyGT",
        "outputId": "7c574750-7fe1-4a49-a4b6-f1c917156460"
      },
      "source": [
        "#word_index\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(embedding_matrix.shape)\n",
        "#X_train[25]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6000, 57)\n",
            "(1500, 57)\n",
            "(15154, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQ7g4iMdV-wm"
      },
      "source": [
        "# create one-hot encoded labels "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4nKVIM8NAy_",
        "outputId": "169487c7-6728-43ff-f0bd-94fb4af8c759"
      },
      "source": [
        "\n",
        "lbl_dict={}\n",
        "index=0\n",
        "# u_label = list(set(train_label))\n",
        "for dial_lbls in train_l:\n",
        "\tif dial_lbls not in lbl_dict:\n",
        "\t\tlbl_dict[dial_lbls]=index\n",
        "\t\tindex=index+1\n",
        "# for i,j in enumerate(u_label):\n",
        "#   lbl_dict[j]=i\n",
        "\n",
        "print(len(lbl_dict))\n",
        "\n",
        "\n",
        "\n",
        "def create_label(label):\n",
        "\t\n",
        "    Y=[]\n",
        "    for i in label:\n",
        "    \txxx=np.zeros(len(lbl_dict))\n",
        "    \tj=lbl_dict.get(i)\n",
        "    \txxx[j]=1\n",
        "    \tY.append(xxx)\n",
        "    return Y\n",
        "\n",
        "label = train_l\n",
        "Y_train = create_label(label)\n",
        "\n",
        "label = test_label\n",
        "Y_test = create_label(label)\n",
        "\n",
        "y_train=np.array([i for i in Y_train])\n",
        "y_test=np.array([i for i in Y_test])\n",
        "\n",
        "embedding_dim = 300"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54WUu0W8Wrn5",
        "outputId": "002e2948-9b2e-4845-921c-242dacbc0183"
      },
      "source": [
        "print(y_test.shape)\n",
        "print(y_test[24])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1500, 7)\n",
            "[1. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PHq_tHkoqXx",
        "outputId": "335fff0e-f91d-4534-9dd2-321ce50822ea"
      },
      "source": [
        "print(lbl_dict)\n",
        "print(list(set(train_l)))\n",
        "print(list(set(test_label)))\n",
        "print(list(set(test_label)-set(train_l)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'SUG': 3, 'OTH': 5, 'REQ': 6, 'STM': 1, 'THT': 4, 'QUE': 2, 'EXP': 0}\n",
            "['SUG', 'OTH', 'REQ', 'STM', 'THT', 'QUE', 'EXP']\n",
            "['OTH', 'SUG', 'REQ', 'STM', 'THT', 'QUE', 'EXP']\n",
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3s7BPdWWJMA"
      },
      "source": [
        "#create model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chxmQP0NNNN7",
        "outputId": "43afdfe2-acfe-4896-df2c-de3195c442f8"
      },
      "source": [
        "print(\"Creating Model...\")\n",
        "inputs = Input(shape=(sequence_length,), dtype='int32')\n",
        "embedding = Embedding(input_dim=len(word_index)+1, output_dim=embedding_dim, weights=[embedding_matrix], input_length=sequence_length)(inputs)\n",
        "conv_0 = Conv1D(filters=64, kernel_size=10, padding='same', kernel_initializer='normal', activation='relu')(embedding)\n",
        "maxpool_0 = MaxPooling1D(pool_size=2)(conv_0)\n",
        "dropout = Dropout(0.1)(maxpool_0)\n",
        "conv_1 = Conv1D(filters=128, kernel_size=10, padding='same', kernel_initializer='normal', activation='relu')(dropout)\n",
        "maxpool_1 = MaxPooling1D(pool_size=2)(conv_1)\n",
        "flatten = Flatten()(maxpool_1)\n",
        "predictions = Dense(1000, activation='relu')(flatten)\n",
        "predictions1 = Dense(len(lbl_dict), activation='softmax')(predictions)\n",
        "adam = Adam(lr=0.01, decay=0.3)\n",
        "model = Model(inputs=inputs, outputs=predictions1)\n",
        "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=4, batch_size=64, validation_data=(X_test, y_test))\n",
        "\n",
        "\n",
        "predicted=model.predict(X_test)\n",
        "#print(\"DONE\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating Model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 6000 samples, validate on 1500 samples\n",
            "Epoch 1/4\n",
            "6000/6000 [==============================] - 26s 4ms/step - loss: 2.8189 - accuracy: 0.5223 - val_loss: 1.2119 - val_accuracy: 0.5800\n",
            "Epoch 2/4\n",
            "6000/6000 [==============================] - 25s 4ms/step - loss: 1.1173 - accuracy: 0.6073 - val_loss: 1.1558 - val_accuracy: 0.6000\n",
            "Epoch 3/4\n",
            "6000/6000 [==============================] - 26s 4ms/step - loss: 1.0237 - accuracy: 0.6377 - val_loss: 1.1301 - val_accuracy: 0.6080\n",
            "Epoch 4/4\n",
            "6000/6000 [==============================] - 25s 4ms/step - loss: 0.9559 - accuracy: 0.6555 - val_loss: 1.1137 - val_accuracy: 0.6127\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd0xwvK0W30R",
        "outputId": "f4d564f2-52c1-48b7-cbe0-bfe4f10af39c"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 57)                0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 57, 300)           4546200   \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 57, 64)            192064    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 28, 64)            0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 28, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 28, 128)           82048     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 14, 128)           0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1792)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1000)              1793000   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 7)                 7007      \n",
            "=================================================================\n",
            "Total params: 6,620,319\n",
            "Trainable params: 6,620,319\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUHRHxNeWNbu"
      },
      "source": [
        "#evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUVmWkFjNgLg",
        "outputId": "b3b68af3-8a08-43a0-eb82-1f6b133809dd"
      },
      "source": [
        "Y_predicted=[]\n",
        "for i in predicted:\n",
        "    pos=i.argmax()\n",
        "    Y_predicted.append(pos)\n",
        "    \n",
        "    \n",
        "    \n",
        "Y_test=[]\n",
        "for i in y_test:\n",
        "    pos=i.argmax()\n",
        "    Y_test.append(pos)\n",
        "    \n",
        "    \n",
        "    \n",
        "from sklearn.metrics import accuracy_score\n",
        "# from sklearn.naive_bayes import GaussianNB\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "# from sklearn.model_selection import cross_val_predict\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(accuracy_score(Y_test, Y_predicted))\n",
        "print(classification_report(Y_test, Y_predicted,digits=4,))\n",
        "print(confusion_matrix(Y_test, Y_predicted))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6126666666666667\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6340    0.9305    0.7541       806\n",
            "           1     0.5254    0.4655    0.4936       333\n",
            "           2     0.0000    0.0000    0.0000       132\n",
            "           3     0.0000    0.0000    0.0000        75\n",
            "           4     0.0000    0.0000    0.0000        53\n",
            "           5     0.6364    0.2258    0.3333        62\n",
            "           6     0.0000    0.0000    0.0000        39\n",
            "\n",
            "   micro avg     0.6127    0.6127    0.6127      1500\n",
            "   macro avg     0.2565    0.2317    0.2259      1500\n",
            "weighted avg     0.4836    0.6127    0.5286      1500\n",
            "\n",
            "[[750  54   0   0   0   2   0]\n",
            " [176 155   0   0   0   2   0]\n",
            " [119  12   0   0   0   1   0]\n",
            " [ 57  17   0   0   0   1   0]\n",
            " [  7  46   0   0   0   0   0]\n",
            " [ 38  10   0   0   0  14   0]\n",
            " [ 36   1   0   0   0   2   0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}